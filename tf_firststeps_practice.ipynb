{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add_2:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.add(3, 5)\n",
    "# Why x, y?\n",
    "# TF automatically names the nodes when you donâ€™t\n",
    "# explicitly name them.\n",
    "x = 3\n",
    "y = 5\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# How to get the value of a?\n",
    "# Create a session, assign it to variable sess so we can call it later\n",
    "# Within the session, evaluate the graph to fetch the value of a\n",
    "import tensorflow as tf\n",
    "a = tf.add(3, 5)\n",
    "sess = tf.Session()\n",
    "print(sess.run(a))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Now condense this a little bit\n",
    "\n",
    "a = tf.add(3, 5)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Session object encapsulates the environment in which Operation objects are executed, and Tensor objects are evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7776\n"
     ]
    }
   ],
   "source": [
    "x = 2\n",
    "y = 3\n",
    "op1 = tf.add(x, y)\n",
    "op2 = tf.multiply(x, y)\n",
    "op3 = tf.pow(op2, op1)\n",
    "with tf.Session() as sess:\n",
    "    op3 = sess.run(op3)\n",
    "\n",
    "print(op3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What happened**\n",
    "\n",
    "![](assets/simple_nn.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15625\n"
     ]
    }
   ],
   "source": [
    "x = 2\n",
    "y = 3\n",
    "add_op = tf.add(x, y)\n",
    "mul_op = tf.multiply(x, y)\n",
    "useless = tf.multiply(x, add_op)\n",
    "pow_op = tf.pow(add_op, mul_op)\n",
    "with tf.Session() as sess:\n",
    "    z = sess.run(pow_op) \n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is happening here?** \n",
    "\n",
    "Draw out what the Tensor Graph on your table with a partner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/useless_nn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Session.run(fetches, feed_dict=None,\n",
    "options=None, run_metadata=None)\n",
    "\n",
    "fetches: A value or list of values to fetch. See tf.Session.run for details of the allowable fetch types.\n",
    "\n",
    "feed_list: (Optional.) A list of feed_dict keys. See tf.Session.run for details of the allowable feed key types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15625\n10\n"
     ]
    }
   ],
   "source": [
    "x = 2\n",
    "y = 3\n",
    "add_op = tf.add(x, y)\n",
    "mul_op = tf.multiply(x, y)\n",
    "useless = tf.multiply(x, add_op)\n",
    "pow_op = tf.pow(add_op, mul_op)\n",
    "with tf.Session() as sess:\n",
    "    z, not_useless = sess.run([pow_op, useless])\n",
    "print(z)\n",
    "print(not_useless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n [ 49.  64.]]\n"
     ]
    }
   ],
   "source": [
    "# Creates a graph.\n",
    "with tf.device('/gpu:2'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "# Creates a session with allow_soft_placement and log_device_placement set\n",
    "# to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"allow_soft_placement=True\" = If you would like TensorFlow to automatically choose an existing and supported device to run the operations in case the specified one doesn't exist, you can set allow_soft_placement to True in the configuration option when creating the session.\n",
    "\n",
    "What am I doing here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible to break graphs into several\n",
    "chunks and run them parallelly\n",
    "across multiple CPUs, GPUs, or\n",
    "devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to specify and call your graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    a = 3\n",
    "    b = 5\n",
    "    x = tf.add(a, b)\n",
    "sess = tf.Session(graph=g) # session is run on the graph g\n",
    "\n",
    "print(sess.run(x))\n",
    "# run session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.get_default_graph()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save computation (only run subgraphs that lead\n",
    "to the values you want to fetch)\n",
    "2. Break computation into small, differential pieces\n",
    "to facilitates auto-differentiation\n",
    "3. Facilitate distributed computation, spread the\n",
    "work across multiple CPUs, GPUs, or devices\n",
    "4. Many common machine learning models are\n",
    "commonly taught and visualized as directed\n",
    "graphs already"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets start visualizing our results on TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
